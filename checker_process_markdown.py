#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸€ä¸ªæ™ºèƒ½å¤„ç† Markdown æ–‡ä»¶çš„è„šæœ¬ã€‚

åŠŸèƒ½:
- è‡ªåŠ¨å¿½ç•¥ YAML Front Matterã€‚
- ä½¿ç”¨ ASTï¼ˆæŠ½è±¡è¯­æ³•æ ‘ï¼‰è§£æ Markdownï¼Œç²¾å‡†è¯†åˆ«å¹¶å¿½ç•¥ä»£ç å—ã€è¡¨æ ¼ç­‰éæ®µè½å†…å®¹ã€‚
-åªæå–æ®µè½ã€åˆ—è¡¨ã€å¼•ç”¨ä¸­çš„æ–‡æœ¬ã€‚
- å°†æå–çš„å†…å®¹æŒ‰å¥å­ï¼ˆä»¥'ã€‚'ã€'ï¼'ã€'ï¼Ÿ'ç»“å°¾ï¼ŒåŒ…æ‹¬ä¸æ‹¬å·çš„ç»„åˆï¼‰åˆ†å‰²ã€‚
- å°†ç»“æœä»¥æ¯å¥ä¸€è¡Œçš„å½¢å¼è¾“å‡ºåˆ°æ–‡æœ¬æ–‡ä»¶ã€‚
"""

import argparse
import os
import re
import sys

try:
    from markdown_it import MarkdownIt
except ImportError as exc:
    print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥æ¨¡å— 'markdown_it'ã€‚", file=sys.stderr)
    print(f"   è¯¦æƒ…: {exc}", file=sys.stderr)
    print("   è¯·ä½¿ç”¨å½“å‰è§£é‡Šå™¨å®‰è£…:", file=sys.stderr)
    print(f"   {sys.executable} -m pip install markdown-it-py", file=sys.stderr)
    sys.exit(1)


def extract_text_from_markdown(file_path: str) -> list[str]:
    """
    è¯»å–Markdownæ–‡ä»¶ï¼Œæ™ºèƒ½æå–å…¶ä¸­çš„çº¯æ–‡æœ¬å†…å®¹ã€‚

    å¤„ç†æµç¨‹:
    1. è¯»å–æ–‡ä»¶å¹¶ç§»é™¤ Front Matterã€‚
    2. ä½¿ç”¨ markdown-it-py å°† Markdown è§£æä¸º token æµã€‚
     3. éå† tokenï¼Œåªæå–æ®µè½å’Œåˆ—è¡¨é¡¹ä¸­çš„æ–‡æœ¬å†…å®¹ã€‚
         è¿™æ ·å¯ä»¥è‡ªç„¶åœ°å¿½ç•¥ä»£ç å—ã€è¡¨æ ¼ã€æ ‡é¢˜ç­‰ã€‚

    Args:
        file_path (str): Markdown æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        list[str]: æå–å‡ºçš„æ–‡æœ¬å—åˆ—è¡¨ï¼ˆæ¯æ®µ/é¡¹ä¸ºä¸€ä¸ªå…ƒç´ ï¼‰ã€‚
    """
    print(f"ğŸ“„ æ­£åœ¨è¯»å–å’Œè§£æè¾“å…¥æ–‡ä»¶: {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ° -> {file_path}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ -> {e}", file=sys.stderr)
        sys.exit(1)

    # 1. ç§»é™¤ Front Matter
    parts = content.split('---', 2)
    if len(parts) == 3 and parts[0].strip() == '':
        print("  - æ£€æµ‹åˆ° Front Matterï¼Œå·²è‡ªåŠ¨å¿½ç•¥ã€‚")
        markdown_body = parts[2]
    else:
        print("  - æœªæ£€æµ‹åˆ° Front Matterï¼Œå°†å¤„ç†æ•´ä¸ªæ–‡ä»¶ã€‚")
        markdown_body = content

    # 2. ä¿æŠ¤è½¬ä¹‰å­—ç¬¦ï¼Œé¿å…è¢« markdown-it-py ç§»é™¤
    # ä½¿ç”¨ \uE000 ä½œä¸ºå ä½ç¬¦ï¼ŒåŒ¹é…åæ–œæ åè·Ÿç€ ASCII æ ‡ç‚¹ç¬¦å·çš„æƒ…å†µ
    # è¿™æ · markdown-it çœ‹åˆ°çš„æ˜¯ "\uE000" + "\X"ï¼Œå®ƒä¼šå°† \X å¤„ç†ä¸ºè½¬ä¹‰å­—ç¬¦ï¼ˆåªä¿ç•™ Xï¼‰ï¼Œ
    # æœ€ç»ˆæˆ‘ä»¬å¾—åˆ° "\uE000" + "X"ï¼Œå†å°†å…¶æ›¿æ¢å› "\X"
    markdown_body = re.sub(
        r'\\([!"#$%&\'()*+,-./:;<=>?@\[\\\]^_`{|}~])', '\uE000' + r'\\\1', markdown_body)

    # 3. ä½¿ç”¨ markdown-it-py è§£æ
    print("  - æ­£åœ¨ä½¿ç”¨ AST è§£æ Markdown ç»“æ„...")
    # å¯ç”¨è¡¨æ ¼æ”¯æŒï¼Œä»¥ä¾¿æ­£ç¡®è¯†åˆ«å’Œè¿‡æ»¤è¡¨æ ¼å†…å®¹
    md = MarkdownIt().enable('table')
    tokens = md.parse(markdown_body)

    # 4. æå–ç›®æ ‡æ–‡æœ¬
    text_blocks = []
    # åªå…³å¿ƒæ®µè½ä¸åˆ—è¡¨é¡¹å†…çš„æ–‡æœ¬
    # 'inline' token åŒ…å«äº†è¯¥å—çš„å®é™…æ–‡æœ¬å†…å®¹

    stack = []

    def _extract_inline_text(inline_token):
        # Rebuild text from inline children, preserving markdown inline styles.
        if not inline_token.children:
            return inline_token.content.replace('\uE000', '\\')
        parts = []
        link_stack = []  # ç”¨äºå¤„ç†é“¾æ¥ [text](url)

        for child in inline_token.children:
            if child.type == "image":
                if link_stack:
                    link_stack[-1]["has_image"] = True
                continue
            elif child.type == "text":
                parts.append(child.content)
            elif child.type == "html_inline":
                parts.append(child.content)
            elif child.type == "code_inline":
                # ä¿ç•™è¡Œå†…ä»£ç çš„åå¼•å·
                parts.append(f"`{child.content}`")
            elif child.type == "strong_open":
                parts.append(child.markup)
            elif child.type == "strong_close":
                parts.append(child.markup)
            elif child.type == "em_open":
                parts.append(child.markup)
            elif child.type == "em_close":
                parts.append(child.markup)
            elif child.type == "link_open":
                # è®°å½•é“¾æ¥å¼€å§‹åœ¨ parts åˆ—è¡¨ä¸­çš„ç´¢å¼•
                href = child.attrGet("href") or ""
                link_stack.append({
                    "parts_index": len(parts),
                    "href": href,
                    "has_image": False
                })
                parts.append("[")
            elif child.type == "link_close":
                if link_stack:
                    link_info = link_stack.pop()
                    if link_info.get("has_image"):
                        # å‘ç°å›¾ç‰‡ï¼Œæ’¤é”€ä» [ å¼€å§‹çš„æ‰€æœ‰æ·»åŠ 
                        parts = parts[:link_info["parts_index"]]
                    else:
                        parts.append("]")
                        parts.append(f"({link_info['href']})")
                else:
                    parts.append("]")
            elif child.type in ("softbreak", "hardbreak"):
                parts.append("\n")
        return "".join(parts).replace('\uE000', '\\')

    for token in tokens:
        if token.nesting == 1:
            stack.append(token.type)
            continue
        if token.nesting == -1:
            if stack:
                stack.pop()
            continue

        if token.type != "inline":
            continue

        inline_text = _extract_inline_text(token).strip()
        if not inline_text:
            continue

        in_paragraph = "paragraph_open" in stack
        in_list_item = "list_item_open" in stack
        in_heading = "heading_open" in stack
        # æ£€æŸ¥æ‰€æœ‰è¡¨æ ¼ç›¸å…³çš„ tokenï¼Œç¡®ä¿å®Œå…¨è¿‡æ»¤è¡¨æ ¼å†…å®¹
        table_tokens = {"table_open", "thead_open",
                        "tbody_open", "tr_open", "th_open", "td_open"}
        in_table = any(t in table_tokens for t in stack)
        in_blockquote = "blockquote_open" in stack

        # åŒ…å«å—å¼•ç”¨å†…å®¹
        if (in_paragraph or in_list_item or in_blockquote) and not in_heading and not in_table:
            text_blocks.append(inline_text)

    print(f"  - æˆåŠŸä» {len(text_blocks)} ä¸ªæ®µè½/åˆ—è¡¨é¡¹/å¼•ç”¨ä¸­æå–æ–‡æœ¬ã€‚")
    return text_blocks


def split_into_sentences(text_blocks: list[str]) -> list[str]:
    """
    å°†æ–‡æœ¬å—åˆ—è¡¨ä¸­çš„å†…å®¹åˆ†å‰²æˆå¥å­ï¼Œå¹¶è¿›è¡Œæ¸…ç†ã€‚

    ç‰¹åˆ«å¤„ç†ï¼š
    - å…¼å®¹ä¸­è‹±æ–‡åˆ†å¥è§„åˆ™ã€‚
    - å½“å¥å·ã€é—®å·ã€æ„Ÿå¹å·ä¸å³ï¼ˆåï¼‰æ‹¬å·æˆ–å¼•å·ï¼ˆå¦‚ â€ã€â€™ã€"ã€'ã€ï¼‰ç­‰ï¼‰ç»„åˆå‡ºç°æ—¶ï¼Œä»¥æœ€åä¸€ä¸ªç¬¦å·ä½œä¸ºæ–­å¥ç‚¹ã€‚
    - è€ƒè™‘ Markdown å†…è”æ ·å¼ï¼ˆåŠ ç²—ã€æ–œä½“ã€åˆ é™¤çº¿ç­‰ï¼‰ï¼Œå¦‚æœæ ·å¼åŒ…è£¹å¤šä¸ªå¥å­ï¼Œä¿æŒæ ·å¼å®Œæ•´æ€§ï¼Œä»¥é•¿çš„ä¸ºæœ€ç»ˆåˆ’åˆ†å¥æ ‡å‡†ã€‚
    - é’ˆå¯¹æ²¡æœ‰æ ‡ç‚¹ç»“å°¾çš„ç‹¬ç«‹æ–‡æœ¬å—ï¼ˆå¦‚æœªåŠ å¥å·çš„åˆ—è¡¨é¡¹ï¼‰ï¼Œä¹Ÿä¼šå°†å…¶ä½œä¸ºç‹¬ç«‹å¥å­ä¿ç•™ã€‚

    Args:
        text_blocks (list[str]): å¾…å¤„ç†çš„æ–‡æœ¬å—åˆ—è¡¨ã€‚

    Returns:
        list[str]: æ¸…ç†å’Œåˆ†å‰²åçš„å¥å­åˆ—è¡¨ã€‚
    """
    print("æ­£åœ¨è¿›è¡Œå¥å­åˆ†å‰²...")

    # å¥æœ«æ ‡ç‚¹çš„æ­£åˆ™è¡¨è¾¾å¼
    sentence_end_pattern = re.compile(
        r'(?:[ã€‚ï¼ï¼Ÿ.!?]+[ï¼‰â€â€™ã€ã€"\'\)\]\}]+|[ï¼‰â€â€™ã€ã€"\'\)\]\}]+[ã€‚ï¼ï¼Ÿ.!?]+|[ã€‚ï¼ï¼Ÿ.!?]+)'
    )

    def find_inline_style_ranges(text: str) -> list[tuple[int, int, str]]:
        """
        æŸ¥æ‰¾æ–‡æœ¬ä¸­æ‰€æœ‰ Markdown å†…è”æ ·å¼çš„åŒºé—´ã€‚

        Returns:
            list[tuple[int, int, str]]: (start_pos, end_pos, marker) åˆ—è¡¨
        """
        ranges = []

        # Markdown å†…è”æ ·å¼æ ‡è®°ï¼ŒæŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œé¿å…åŒ¹é…å†²çª
        # æ ¼å¼: (marker, is_symmetric)
        markers = [
            ('***', True),   # åŠ ç²—æ–œä½“
            ('**', True),    # åŠ ç²—
            ('~~', True),    # åˆ é™¤çº¿
            ('*', True),     # æ–œä½“
            ('_', True),     # æ–œä½“ï¼ˆä¸‹åˆ’çº¿ï¼‰
        ]

        for marker, is_symmetric in markers:
            marker_len = len(marker)
            pos = 0

            while pos < len(text):
                # æŸ¥æ‰¾å¼€å§‹æ ‡è®°
                start = text.find(marker, pos)
                if start == -1:
                    break

                # æŸ¥æ‰¾ç»“æŸæ ‡è®°
                end_search_start = start + marker_len
                end = text.find(marker, end_search_start)

                if end == -1:
                    # æ²¡æœ‰æ‰¾åˆ°ç»“æŸæ ‡è®°ï¼Œè·³è¿‡æ­¤å¼€å§‹æ ‡è®°
                    pos = start + 1
                    continue

                # è®°å½•åŒºé—´ [start, end + marker_len)
                ranges.append((start, end + marker_len, marker))
                pos = end + marker_len

        # æŒ‰å¼€å§‹ä½ç½®æ’åº
        ranges.sort(key=lambda x: x[0])
        return ranges

    def is_inside_style(pos: int, style_ranges: list[tuple[int, int, str]]) -> tuple[bool, int]:
        """
        æ£€æŸ¥ä½ç½® pos æ˜¯å¦åœ¨æŸä¸ªæ ·å¼åŒºé—´å†…ã€‚

        Returns:
            (is_inside, style_end): å¦‚æœåœ¨æ ·å¼å†…ï¼Œè¿”å›(True, æ ·å¼ç»“æŸä½ç½®)ï¼Œå¦åˆ™(False, pos)
        """
        for start, end, marker in style_ranges:
            if start < pos < end:
                return True, end
        return False, pos

    def find_sentence_boundary(text: str, start_pos: int, style_ranges: list[tuple[int, int, str]]) -> int:
        """
        ä» start_pos å¼€å§‹æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå¥å­çš„ç»“æŸä½ç½®ã€‚
        è€ƒè™‘å¥æœ«æ ‡ç‚¹å’Œ Markdown å†…è”æ ·å¼ï¼Œä»¥è¾ƒé•¿çš„è¾¹ç•Œä¸ºå‡†ã€‚

        Returns:
            å¥å­ç»“æŸä½ç½®çš„ç´¢å¼•ï¼ˆä¸åŒ…å«è¯¥ä½ç½®ï¼‰ã€‚
        """
        search_text = text[start_pos:]
        match = sentence_end_pattern.search(search_text)

        if not match:
            # æ²¡æœ‰æ‰¾åˆ°å¥æœ«æ ‡ç‚¹ï¼Œè¿”å›æ–‡æœ¬ç»“æŸä½ç½®
            return len(text)

        # å¥æœ«æ ‡ç‚¹çš„ç»å¯¹ç»“æŸä½ç½®
        punctuation_end = start_pos + match.end()

        # æ£€æŸ¥æ ‡ç‚¹ä½ç½®æ˜¯å¦åœ¨æŸä¸ªå†…è”æ ·å¼ä¸­
        is_inside, style_end = is_inside_style(
            punctuation_end - 1, style_ranges)

        if is_inside:
            # åœ¨æ ·å¼å†…ï¼Œä½¿ç”¨æ ·å¼ç»“æŸä½ç½®
            return style_end
        else:
            # ä¸åœ¨æ ·å¼å†…ï¼Œä½¿ç”¨æ ‡ç‚¹ä½ç½®
            return punctuation_end

    cleaned_sentences = []

    for block in text_blocks:
        # 1. å…ˆåœ¨æ•´ä¸ªæ–‡æœ¬å—ä¸­è¿‡æ»¤æ‰å¯èƒ½è·¨è¡Œçš„å…¬å¼å— $$...$$
        block = re.sub(r'\$\$.+?\$\$', '', block, flags=re.DOTALL)

        # 2. å°†å¤„ç†åçš„æ–‡æœ¬å—æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
        sub_lines = block.split('\n')

        for text in sub_lines:
            text = text.strip()
            if not text:
                continue

            # è¯†åˆ«æ‰€æœ‰å†…è”æ ·å¼åŒºé—´
            style_ranges = find_inline_style_ranges(text)

            # ä½¿ç”¨æ–°çš„åˆ†å¥é€»è¾‘
            pos = 0
            while pos < len(text):
                end_pos = find_sentence_boundary(text, pos, style_ranges)
                sentence = text[pos:end_pos].strip()

                if sentence:
                    # å°†å¤šä¸ªè¿ç»­ç©ºæ ¼å‹ç¼©ä¸ºå•ä¸ªç©ºæ ¼
                    sentence = re.sub(r'\s+', ' ', sentence)
                    cleaned_sentences.append(sentence)

                if end_pos == pos:
                    # é˜²æ­¢æ— é™å¾ªç¯
                    pos += 1
                else:
                    pos = end_pos

    print(f"  - æˆåŠŸåˆ†å‰²å‡º {len(cleaned_sentences)} ä¸ªå¥å­ã€‚")
    return cleaned_sentences


def write_to_txt(sentences: list[str], output_path: str, source_file_path: str):
    """
    å°†å¥å­åˆ—è¡¨å†™å…¥æŒ‡å®šçš„æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯å¥ä¸€è¡Œã€‚

        é¢å¤–è¯´æ˜:
        - ä¸ºäº†ä¾¿äºå®šä½ï¼Œæ¯å¥å‰ä¼šæ·»åŠ å¯è¿‡æ»¤çš„æ ‡ç­¾ï¼Œæ ¼å¼ä¸º: "@@S000001|filename.md@@ "ã€‚
            è¯¥æ ‡ç­¾ä½¿ç”¨å›ºå®šå‰ç¼€å’Œé›¶å¡«å……æ•°å­—ï¼Œå¹¶åŒ…å«æ¥æºæ–‡ä»¶åï¼Œæ–¹ä¾¿å®šä½ã€‚

    Args:
        sentences (list[str]): å¥å­åˆ—è¡¨ã€‚
        output_path (str): è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚
        source_file_path (str): æ¥æº Markdown æ–‡ä»¶è·¯å¾„ã€‚
    """
    print(f"æ­£åœ¨å†™å…¥ç»“æœåˆ°: {output_path}")
    try:
        source_name = os.path.basename(source_file_path)
        with open(output_path, 'w', encoding='utf-8') as f:
            if not sentences:
                f.write("")  # å†™å…¥ç©ºæ–‡ä»¶
            else:
                tagged_lines = []
                for idx, sentence in enumerate(sentences, start=1):
                    tag = f"@@S{idx:06d}|{source_name}@@ "
                    tagged_lines.append(tag + sentence)
                f.write('\n'.join(tagged_lines) + '\n')
    except Exception as e:
        print(f"âŒ é”™è¯¯: å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ -> {e}", file=sys.stderr)
        sys.exit(1)


def main():
    """
    ä¸»å‡½æ•°ï¼Œç¼–æ’æ•´ä¸ªå¤„ç†æµç¨‹ã€‚
    """
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½å¤„ç† Markdownæ–‡ä»¶ï¼šå¿½ç•¥ä»£ç /è¡¨æ ¼ï¼Œæå–æ®µè½å†…å®¹å¹¶æŒ‰å¥åˆ†å‰²ã€‚",
        epilog="ç¤ºä¾‹: python checker_process_markdown.py my_article.md output.txt"
    )
    parser.add_argument("input_file", help="è¦å¤„ç†çš„ Markdown æ–‡ä»¶ååŠè·¯å¾„ã€‚")
    parser.add_argument("output_file", help="å¯¼å‡ºçš„ txt æ–‡ä»¶ååŠè·¯å¾„ã€‚")

    args = parser.parse_args()

    # æ ¸å¿ƒå¤„ç†æµç¨‹
    extracted_text = extract_text_from_markdown(args.input_file)
    sentences_list = split_into_sentences(extracted_text)
    write_to_txt(sentences_list, args.output_file, args.input_file)

    print("\nğŸ‰å…¨éƒ¨å¤„ç†å®Œæˆï¼ç»“æœå·²æˆåŠŸä¿å­˜ã€‚")


if __name__ == "__main__":
    main()
